{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lab2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HLERco7j7oj3",
        "outputId": "e6270f54-377d-4cfa-a955-9856761dd53a"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sat Feb 13 19:45:22 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.39       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   56C    P8    10W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YBiWbhsy7vW0",
        "outputId": "d5a7da68-f213-4a44-a22c-ca9a988fe464"
      },
      "source": [
        "# FSDL Spring 2021 Setup\r\n",
        "!git clone https://github.com/full-stack-deep-learning/fsdl-text-recognizer-2021-labs\r\n",
        "%cd fsdl-text-recognizer-2021-labs\r\n",
        "!pip install pytorch_lightning\r\n",
        "%env PYTHONPATH=.:$PYTHONPATH"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'fsdl-text-recognizer-2021-labs'...\n",
            "remote: Enumerating objects: 207, done.\u001b[K\n",
            "remote: Counting objects: 100% (207/207), done.\u001b[K\n",
            "remote: Compressing objects: 100% (153/153), done.\u001b[K\n",
            "remote: Total 207 (delta 76), reused 175 (delta 49), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (207/207), 2.88 MiB | 17.06 MiB/s, done.\n",
            "Resolving deltas: 100% (76/76), done.\n",
            "/content/fsdl-text-recognizer-2021-labs\n",
            "Collecting pytorch_lightning\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e7/d4/d2751586c7961f238a6077a6dc6e4a9214445da3219f463aa44b29fe4b42/pytorch_lightning-1.1.8-py3-none-any.whl (696kB)\n",
            "\u001b[K     |████████████████████████████████| 696kB 8.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch>=1.3 in /usr/local/lib/python3.6/dist-packages (from pytorch_lightning) (1.7.0+cu101)\n",
            "Collecting PyYAML!=5.4.*,>=5.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/64/c2/b80047c7ac2478f9501676c988a5411ed5572f35d1beff9cae07d321512c/PyYAML-5.3.1.tar.gz (269kB)\n",
            "\u001b[K     |████████████████████████████████| 276kB 18.4MB/s \n",
            "\u001b[?25hCollecting future>=0.17.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/45/0b/38b06fd9b92dc2b68d58b75f900e97884c45bedd2ff83203d933cf5851c9/future-0.18.2.tar.gz (829kB)\n",
            "\u001b[K     |████████████████████████████████| 829kB 26.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.16.6 in /usr/local/lib/python3.6/dist-packages (from pytorch_lightning) (1.19.5)\n",
            "Collecting fsspec[http]>=0.8.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ec/80/72ac0982cc833945fada4b76c52f0f65435ba4d53bc9317d1c70b5f7e7d5/fsspec-0.8.5-py3-none-any.whl (98kB)\n",
            "\u001b[K     |████████████████████████████████| 102kB 14.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.6/dist-packages (from pytorch_lightning) (4.41.1)\n",
            "Requirement already satisfied: tensorboard>=2.2.0 in /usr/local/lib/python3.6/dist-packages (from pytorch_lightning) (2.4.1)\n",
            "Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from torch>=1.3->pytorch_lightning) (0.8)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch>=1.3->pytorch_lightning) (3.7.4.3)\n",
            "Collecting aiohttp; extra == \"http\"\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ad/e6/d4b6235d776c9b33f853e603efede5aac5a34f71ca9d3877adb30492eb4e/aiohttp-3.7.3-cp36-cp36m-manylinux2014_x86_64.whl (1.3MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3MB 34.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests; extra == \"http\" in /usr/local/lib/python3.6/dist-packages (from fsspec[http]>=0.8.1->pytorch_lightning) (2.23.0)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (1.32.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (1.8.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (0.10.0)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (3.12.4)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (1.15.0)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (0.36.2)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (1.25.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (53.0.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (1.0.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (0.4.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (3.3.3)\n",
            "Requirement already satisfied: chardet<4.0,>=2.0 in /usr/local/lib/python3.6/dist-packages (from aiohttp; extra == \"http\"->fsspec[http]>=0.8.1->pytorch_lightning) (3.0.4)\n",
            "Collecting yarl<2.0,>=1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/da/08/52b26b44bce7b818b410aee37c5e424c9ea420c557bca97dc2adac29b151/yarl-1.6.3-cp36-cp36m-manylinux2014_x86_64.whl (293kB)\n",
            "\u001b[K     |████████████████████████████████| 296kB 55.7MB/s \n",
            "\u001b[?25hCollecting async-timeout<4.0,>=3.0\n",
            "  Downloading https://files.pythonhosted.org/packages/e1/1e/5a4441be21b0726c4464f3f23c8b19628372f606755a9d2e46c187e65ec4/async_timeout-3.0.1-py3-none-any.whl\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.6/dist-packages (from aiohttp; extra == \"http\"->fsspec[http]>=0.8.1->pytorch_lightning) (20.3.0)\n",
            "Collecting idna-ssl>=1.0; python_version < \"3.7\"\n",
            "  Downloading https://files.pythonhosted.org/packages/46/03/07c4894aae38b0de52b52586b24bf189bb83e4ddabfe2e2c8f2419eec6f4/idna-ssl-1.1.0.tar.gz\n",
            "Collecting multidict<7.0,>=4.5\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a1/35/b22524d6b9cacfb4c5eff413a069bbc17c6ea628e54da5c6c989998ced5f/multidict-5.1.0-cp36-cp36m-manylinux2014_x86_64.whl (141kB)\n",
            "\u001b[K     |████████████████████████████████| 143kB 52.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests; extra == \"http\"->fsspec[http]>=0.8.1->pytorch_lightning) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests; extra == \"http\"->fsspec[http]>=0.8.1->pytorch_lightning) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests; extra == \"http\"->fsspec[http]>=0.8.1->pytorch_lightning) (1.24.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=2.2.0->pytorch_lightning) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=2.2.0->pytorch_lightning) (4.2.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=2.2.0->pytorch_lightning) (4.7)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch_lightning) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard>=2.2.0->pytorch_lightning) (3.4.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard>=2.2.0->pytorch_lightning) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch_lightning) (3.1.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard>=2.2.0->pytorch_lightning) (3.4.0)\n",
            "Building wheels for collected packages: PyYAML, future, idna-ssl\n",
            "  Building wheel for PyYAML (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for PyYAML: filename=PyYAML-5.3.1-cp36-cp36m-linux_x86_64.whl size=44621 sha256=320cba2d3ab4567bee0cb3ef2e668e425274a82d16e15db6712ec8432ce9d983\n",
            "  Stored in directory: /root/.cache/pip/wheels/a7/c1/ea/cf5bd31012e735dc1dfea3131a2d5eae7978b251083d6247bd\n",
            "  Building wheel for future (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for future: filename=future-0.18.2-cp36-none-any.whl size=491057 sha256=eb444384057017eb82d984b4f96def224342fc7183c7586f62a2820c900b6351\n",
            "  Stored in directory: /root/.cache/pip/wheels/8b/99/a0/81daf51dcd359a9377b110a8a886b3895921802d2fc1b2397e\n",
            "  Building wheel for idna-ssl (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for idna-ssl: filename=idna_ssl-1.1.0-cp36-none-any.whl size=3163 sha256=5e78784dea683c1642f9bda7fae43d5c7a52f24b62fcb67930b14f222f428a12\n",
            "  Stored in directory: /root/.cache/pip/wheels/d3/00/b3/32d613e19e08a739751dd6bf998cfed277728f8b2127ad4eb7\n",
            "Successfully built PyYAML future idna-ssl\n",
            "Installing collected packages: PyYAML, future, multidict, yarl, async-timeout, idna-ssl, aiohttp, fsspec, pytorch-lightning\n",
            "  Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "  Found existing installation: future 0.16.0\n",
            "    Uninstalling future-0.16.0:\n",
            "      Successfully uninstalled future-0.16.0\n",
            "Successfully installed PyYAML-5.3.1 aiohttp-3.7.3 async-timeout-3.0.1 fsspec-0.8.5 future-0.18.2 idna-ssl-1.1.0 multidict-5.1.0 pytorch-lightning-1.1.8 yarl-1.6.3\n",
            "env: PYTHONPATH=.:$PYTHONPATH\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BFFacBLH72zu",
        "outputId": "294f642d-a15d-44f7-d219-65e377993447"
      },
      "source": [
        "cd lab2"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/fsdl-text-recognizer-2021-labs/lab2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BFJPD1t58NXe",
        "outputId": "4cc0a66c-f7ba-42d4-8c4d-4b394fb2dcb1"
      },
      "source": [
        "!python3 training/run_experiment.py --model_class=CNN --data_class=MNIST --max_epochs=5 --gpus=1"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/pytorch_lightning/utilities/distributed.py:50: UserWarning: You have set progress_bar_refresh_rate < 20 on Google Colab. This may crash. Consider using progress_bar_refresh_rate >= 20 in Trainer.\n",
            "  warnings.warn(*args, **kwargs)\n",
            "GPU available: True, used: True\n",
            "TPU available: None, using: 0 TPU cores\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to /content/fsdl-text-recognizer-2021-labs/data/downloaded/MNIST/raw/train-images-idx3-ubyte.gz\n",
            "9920512it [00:01, 9253017.19it/s]                 \n",
            "Extracting /content/fsdl-text-recognizer-2021-labs/data/downloaded/MNIST/raw/train-images-idx3-ubyte.gz to /content/fsdl-text-recognizer-2021-labs/data/downloaded/MNIST/raw\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to /content/fsdl-text-recognizer-2021-labs/data/downloaded/MNIST/raw/train-labels-idx1-ubyte.gz\n",
            "32768it [00:00, 131063.63it/s]\n",
            "Extracting /content/fsdl-text-recognizer-2021-labs/data/downloaded/MNIST/raw/train-labels-idx1-ubyte.gz to /content/fsdl-text-recognizer-2021-labs/data/downloaded/MNIST/raw\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to /content/fsdl-text-recognizer-2021-labs/data/downloaded/MNIST/raw/t10k-images-idx3-ubyte.gz\n",
            "1654784it [00:00, 1697654.15it/s]               \n",
            "Extracting /content/fsdl-text-recognizer-2021-labs/data/downloaded/MNIST/raw/t10k-images-idx3-ubyte.gz to /content/fsdl-text-recognizer-2021-labs/data/downloaded/MNIST/raw\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to /content/fsdl-text-recognizer-2021-labs/data/downloaded/MNIST/raw/t10k-labels-idx1-ubyte.gz\n",
            "8192it [00:00, 12928.05it/s]\n",
            "Extracting /content/fsdl-text-recognizer-2021-labs/data/downloaded/MNIST/raw/t10k-labels-idx1-ubyte.gz to /content/fsdl-text-recognizer-2021-labs/data/downloaded/MNIST/raw\n",
            "Processing...\n",
            "/usr/local/lib/python3.6/dist-packages/torchvision/datasets/mnist.py:480: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
            "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n",
            "Done!\n",
            "2021-02-13 19:48:42.099347: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
            "\n",
            "   | Name             | Type      | Params\n",
            "------------------------------------------------\n",
            "0  | model            | CNN       | 1.6 M \n",
            "1  | model.conv1      | ConvBlock | 640   \n",
            "2  | model.conv1.conv | Conv2d    | 640   \n",
            "3  | model.conv1.relu | ReLU      | 0     \n",
            "4  | model.conv2      | ConvBlock | 36.9 K\n",
            "5  | model.conv2.conv | Conv2d    | 36.9 K\n",
            "6  | model.conv2.relu | ReLU      | 0     \n",
            "7  | model.dropout    | Dropout   | 0     \n",
            "8  | model.max_pool   | MaxPool2d | 0     \n",
            "9  | model.fc1        | Linear    | 1.6 M \n",
            "10 | model.fc2        | Linear    | 1.3 K \n",
            "11 | train_acc        | Accuracy  | 0     \n",
            "12 | val_acc          | Accuracy  | 0     \n",
            "13 | test_acc         | Accuracy  | 0     \n",
            "------------------------------------------------\n",
            "1.6 M     Trainable params\n",
            "0         Non-trainable params\n",
            "1.6 M     Total params\n",
            "Epoch 0:  91% 430/470 [00:16<00:01, 26.79it/s, loss=0.0602, v_num=0, val_loss=2.3, val_acc=0.133]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Epoch 0:  92% 434/470 [00:16<00:01, 26.83it/s, loss=0.0602, v_num=0, val_loss=2.3, val_acc=0.133]\n",
            "Epoch 0:  93% 438/470 [00:16<00:01, 26.86it/s, loss=0.0602, v_num=0, val_loss=2.3, val_acc=0.133]\n",
            "Epoch 0:  94% 442/470 [00:16<00:01, 26.92it/s, loss=0.0602, v_num=0, val_loss=2.3, val_acc=0.133]\n",
            "Validating:  30% 12/40 [00:00<00:00, 33.58it/s]\u001b[A\n",
            "Epoch 0:  95% 446/470 [00:16<00:00, 26.95it/s, loss=0.0602, v_num=0, val_loss=2.3, val_acc=0.133]\n",
            "Epoch 0:  96% 450/470 [00:16<00:00, 27.00it/s, loss=0.0602, v_num=0, val_loss=2.3, val_acc=0.133]\n",
            "Epoch 0:  97% 454/470 [00:16<00:00, 27.05it/s, loss=0.0602, v_num=0, val_loss=2.3, val_acc=0.133]\n",
            "Epoch 0:  97% 458/470 [00:16<00:00, 27.10it/s, loss=0.0602, v_num=0, val_loss=2.3, val_acc=0.133]\n",
            "Epoch 0:  98% 462/470 [00:17<00:00, 27.15it/s, loss=0.0602, v_num=0, val_loss=2.3, val_acc=0.133]\n",
            "Epoch 0:  99% 466/470 [00:17<00:00, 27.20it/s, loss=0.0602, v_num=0, val_loss=2.3, val_acc=0.133]\n",
            "Epoch 0: 100% 470/470 [00:17<00:00, 27.09it/s, loss=0.0602, v_num=0, val_loss=0.0653, val_acc=0.983]\n",
            "Epoch 1:  91% 430/470 [00:15<00:01, 27.22it/s, loss=0.0287, v_num=0, val_loss=0.0653, val_acc=0.983]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Epoch 1:  92% 433/470 [00:15<00:01, 27.27it/s, loss=0.0287, v_num=0, val_loss=0.0653, val_acc=0.983]\n",
            "Epoch 1:  93% 438/470 [00:16<00:01, 27.37it/s, loss=0.0287, v_num=0, val_loss=0.0653, val_acc=0.983]\n",
            "Epoch 1:  94% 443/470 [00:16<00:00, 27.47it/s, loss=0.0287, v_num=0, val_loss=0.0653, val_acc=0.983]\n",
            "Validating:  32% 13/40 [00:00<00:00, 39.65it/s]\u001b[A\n",
            "Epoch 1:  95% 448/470 [00:16<00:00, 27.55it/s, loss=0.0287, v_num=0, val_loss=0.0653, val_acc=0.983]\n",
            "Epoch 1:  96% 453/470 [00:16<00:00, 27.66it/s, loss=0.0287, v_num=0, val_loss=0.0653, val_acc=0.983]\n",
            "Epoch 1:  97% 458/470 [00:16<00:00, 27.73it/s, loss=0.0287, v_num=0, val_loss=0.0653, val_acc=0.983]\n",
            "Epoch 1:  99% 463/470 [00:16<00:00, 27.81it/s, loss=0.0287, v_num=0, val_loss=0.0653, val_acc=0.983]\n",
            "Epoch 1: 100% 468/470 [00:16<00:00, 27.88it/s, loss=0.0287, v_num=0, val_loss=0.0653, val_acc=0.983]\n",
            "Epoch 1: 100% 470/470 [00:16<00:00, 27.79it/s, loss=0.0287, v_num=0, val_loss=0.0509, val_acc=0.986]\n",
            "Epoch 2:  91% 430/470 [00:15<00:01, 28.00it/s, loss=0.0224, v_num=0, val_loss=0.0509, val_acc=0.986]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/40 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 2:  93% 435/470 [00:15<00:01, 28.01it/s, loss=0.0224, v_num=0, val_loss=0.0509, val_acc=0.986]\n",
            "Epoch 2:  94% 440/470 [00:15<00:01, 28.10it/s, loss=0.0224, v_num=0, val_loss=0.0509, val_acc=0.986]\n",
            "Epoch 2:  95% 445/470 [00:15<00:00, 28.17it/s, loss=0.0224, v_num=0, val_loss=0.0509, val_acc=0.986]\n",
            "Epoch 2:  96% 450/470 [00:15<00:00, 28.26it/s, loss=0.0224, v_num=0, val_loss=0.0509, val_acc=0.986]\n",
            "Epoch 2:  97% 455/470 [00:16<00:00, 28.35it/s, loss=0.0224, v_num=0, val_loss=0.0509, val_acc=0.986]\n",
            "Epoch 2:  98% 460/470 [00:16<00:00, 28.45it/s, loss=0.0224, v_num=0, val_loss=0.0509, val_acc=0.986]\n",
            "Epoch 2:  99% 465/470 [00:16<00:00, 28.54it/s, loss=0.0224, v_num=0, val_loss=0.0509, val_acc=0.986]\n",
            "Epoch 2: 100% 470/470 [00:16<00:00, 28.63it/s, loss=0.0224, v_num=0, val_loss=0.0509, val_acc=0.986]\n",
            "Epoch 2: 100% 470/470 [00:16<00:00, 28.50it/s, loss=0.0224, v_num=0, val_loss=0.0441, val_acc=0.987]\n",
            "Epoch 3:  91% 430/470 [00:15<00:01, 27.10it/s, loss=0.021, v_num=0, val_loss=0.0441, val_acc=0.987] \n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Epoch 3:  93% 435/470 [00:15<00:01, 27.19it/s, loss=0.021, v_num=0, val_loss=0.0441, val_acc=0.987]\n",
            "Validating:  12% 5/40 [00:00<00:00, 42.29it/s]\u001b[A\n",
            "Epoch 3:  94% 440/470 [00:16<00:01, 27.28it/s, loss=0.021, v_num=0, val_loss=0.0441, val_acc=0.987]\n",
            "Epoch 3:  95% 445/470 [00:16<00:00, 27.36it/s, loss=0.021, v_num=0, val_loss=0.0441, val_acc=0.987]\n",
            "Epoch 3:  96% 450/470 [00:16<00:00, 27.42it/s, loss=0.021, v_num=0, val_loss=0.0441, val_acc=0.987]\n",
            "Epoch 3:  97% 455/470 [00:16<00:00, 27.46it/s, loss=0.021, v_num=0, val_loss=0.0441, val_acc=0.987]\n",
            "Validating:  62% 25/40 [00:00<00:00, 34.42it/s]\u001b[A\n",
            "Epoch 3:  98% 460/470 [00:16<00:00, 27.51it/s, loss=0.021, v_num=0, val_loss=0.0441, val_acc=0.987]\n",
            "Epoch 3:  99% 465/470 [00:16<00:00, 27.56it/s, loss=0.021, v_num=0, val_loss=0.0441, val_acc=0.987]\n",
            "Epoch 3: 100% 470/470 [00:17<00:00, 27.52it/s, loss=0.021, v_num=0, val_loss=0.0379, val_acc=0.989]\n",
            "Epoch 4:  91% 430/470 [00:16<00:01, 26.08it/s, loss=0.0124, v_num=0, val_loss=0.0379, val_acc=0.989]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Epoch 4:  93% 435/470 [00:16<00:01, 26.18it/s, loss=0.0124, v_num=0, val_loss=0.0379, val_acc=0.989]\n",
            "Validating:  12% 5/40 [00:00<00:00, 40.08it/s]\u001b[A\n",
            "Epoch 4:  94% 440/470 [00:16<00:01, 26.28it/s, loss=0.0124, v_num=0, val_loss=0.0379, val_acc=0.989]\n",
            "Epoch 4:  95% 445/470 [00:16<00:00, 26.39it/s, loss=0.0124, v_num=0, val_loss=0.0379, val_acc=0.989]\n",
            "Epoch 4:  96% 450/470 [00:16<00:00, 26.50it/s, loss=0.0124, v_num=0, val_loss=0.0379, val_acc=0.989]\n",
            "Epoch 4:  97% 455/470 [00:17<00:00, 26.60it/s, loss=0.0124, v_num=0, val_loss=0.0379, val_acc=0.989]\n",
            "Epoch 4:  98% 460/470 [00:17<00:00, 26.71it/s, loss=0.0124, v_num=0, val_loss=0.0379, val_acc=0.989]\n",
            "Epoch 4:  99% 465/470 [00:17<00:00, 26.79it/s, loss=0.0124, v_num=0, val_loss=0.0379, val_acc=0.989]\n",
            "Epoch 4: 100% 470/470 [00:17<00:00, 26.87it/s, loss=0.0124, v_num=0, val_loss=0.0441, val_acc=0.987]\n",
            "Epoch 4: 100% 470/470 [00:17<00:00, 26.87it/s, loss=0.0124, v_num=0, val_loss=0.0441, val_acc=0.987]\n",
            "Testing: 100% 79/79 [00:01<00:00, 39.61it/s]\n",
            "--------------------------------------------------------------------------------\n",
            "DATALOADER:0 TEST RESULTS\n",
            "{'test_acc': 0.9879000186920166}\n",
            "--------------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EFwF85QU9BNt",
        "outputId": "1c2c5dc6-af15-4d91-fb58-a27b1e0e6cce"
      },
      "source": [
        "!python3 training/run_experiment.py --model_class=CNN --data_class=EMNIST --max_epochs=5 --gpus=1"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/pytorch_lightning/utilities/distributed.py:50: UserWarning: You have set progress_bar_refresh_rate < 20 on Google Colab. This may crash. Consider using progress_bar_refresh_rate >= 20 in Trainer.\n",
            "  warnings.warn(*args, **kwargs)\n",
            "GPU available: True, used: True\n",
            "TPU available: None, using: 0 TPU cores\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "Downloading raw dataset from https://s3-us-west-2.amazonaws.com/fsdl-public-assets/matlab.zip to /content/fsdl-text-recognizer-2021-labs/data/downloaded/emnist/matlab.zip...\n",
            "709MB [00:08, 87.3MB/s]               \n",
            "Computing SHA-256...\n",
            "Unzipping EMNIST...\n",
            "Loading training data from .mat file\n",
            "Balancing classes to reduce amount of data\n",
            "Saving to HDF5 in a compressed format...\n",
            "Saving essential dataset parameters to text_recognizer/datasets...\n",
            "Cleaning up...\n",
            "2021-02-13 19:51:59.534681: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
            "\n",
            "   | Name             | Type      | Params\n",
            "------------------------------------------------\n",
            "0  | model            | CNN       | 1.7 M \n",
            "1  | model.conv1      | ConvBlock | 640   \n",
            "2  | model.conv1.conv | Conv2d    | 640   \n",
            "3  | model.conv1.relu | ReLU      | 0     \n",
            "4  | model.conv2      | ConvBlock | 36.9 K\n",
            "5  | model.conv2.conv | Conv2d    | 36.9 K\n",
            "6  | model.conv2.relu | ReLU      | 0     \n",
            "7  | model.dropout    | Dropout   | 0     \n",
            "8  | model.max_pool   | MaxPool2d | 0     \n",
            "9  | model.fc1        | Linear    | 1.6 M \n",
            "10 | model.fc2        | Linear    | 10.7 K\n",
            "11 | train_acc        | Accuracy  | 0     \n",
            "12 | val_acc          | Accuracy  | 0     \n",
            "13 | test_acc         | Accuracy  | 0     \n",
            "------------------------------------------------\n",
            "1.7 M     Trainable params\n",
            "0         Non-trainable params\n",
            "1.7 M     Total params\n",
            "Epoch 0:  80% 2033/2542 [00:30<00:07, 66.66it/s, loss=0.57, v_num=1, val_loss=4.41, val_acc=0.0195] \n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Epoch 0:  80% 2035/2542 [00:30<00:07, 66.40it/s, loss=0.57, v_num=1, val_loss=4.41, val_acc=0.0195]\n",
            "Epoch 0:  81% 2050/2542 [00:30<00:07, 66.66it/s, loss=0.57, v_num=1, val_loss=4.41, val_acc=0.0195]\n",
            "Epoch 0:  81% 2065/2542 [00:30<00:07, 66.93it/s, loss=0.57, v_num=1, val_loss=4.41, val_acc=0.0195]\n",
            "Epoch 0:  82% 2081/2542 [00:30<00:06, 67.21it/s, loss=0.57, v_num=1, val_loss=4.41, val_acc=0.0195]\n",
            "Epoch 0:  82% 2097/2542 [00:31<00:06, 67.48it/s, loss=0.57, v_num=1, val_loss=4.41, val_acc=0.0195]\n",
            "Epoch 0:  83% 2113/2542 [00:31<00:06, 67.76it/s, loss=0.57, v_num=1, val_loss=4.41, val_acc=0.0195]\n",
            "Epoch 0:  84% 2129/2542 [00:31<00:06, 68.04it/s, loss=0.57, v_num=1, val_loss=4.41, val_acc=0.0195]\n",
            "Epoch 0:  84% 2145/2542 [00:31<00:05, 68.31it/s, loss=0.57, v_num=1, val_loss=4.41, val_acc=0.0195]\n",
            "Epoch 0:  85% 2161/2542 [00:31<00:05, 68.59it/s, loss=0.57, v_num=1, val_loss=4.41, val_acc=0.0195]\n",
            "Epoch 0:  86% 2177/2542 [00:31<00:05, 68.87it/s, loss=0.57, v_num=1, val_loss=4.41, val_acc=0.0195]\n",
            "Epoch 0:  86% 2193/2542 [00:31<00:05, 69.13it/s, loss=0.57, v_num=1, val_loss=4.41, val_acc=0.0195]\n",
            "Epoch 0:  87% 2209/2542 [00:31<00:04, 69.40it/s, loss=0.57, v_num=1, val_loss=4.41, val_acc=0.0195]\n",
            "Epoch 0:  88% 2225/2542 [00:31<00:04, 69.67it/s, loss=0.57, v_num=1, val_loss=4.41, val_acc=0.0195]\n",
            "Epoch 0:  88% 2241/2542 [00:32<00:04, 69.92it/s, loss=0.57, v_num=1, val_loss=4.41, val_acc=0.0195]\n",
            "Epoch 0:  89% 2257/2542 [00:32<00:04, 70.19it/s, loss=0.57, v_num=1, val_loss=4.41, val_acc=0.0195]\n",
            "Epoch 0:  89% 2273/2542 [00:32<00:03, 70.45it/s, loss=0.57, v_num=1, val_loss=4.41, val_acc=0.0195]\n",
            "Epoch 0:  90% 2289/2542 [00:32<00:03, 70.69it/s, loss=0.57, v_num=1, val_loss=4.41, val_acc=0.0195]\n",
            "Epoch 0:  91% 2305/2542 [00:32<00:03, 70.91it/s, loss=0.57, v_num=1, val_loss=4.41, val_acc=0.0195]\n",
            "Epoch 0:  91% 2321/2542 [00:32<00:03, 71.11it/s, loss=0.57, v_num=1, val_loss=4.41, val_acc=0.0195]\n",
            "Validating:  57% 288/509 [00:02<00:01, 132.02it/s]\u001b[A\n",
            "Epoch 0:  92% 2337/2542 [00:32<00:02, 71.32it/s, loss=0.57, v_num=1, val_loss=4.41, val_acc=0.0195]\n",
            "Epoch 0:  93% 2353/2542 [00:32<00:02, 71.52it/s, loss=0.57, v_num=1, val_loss=4.41, val_acc=0.0195]\n",
            "Epoch 0:  93% 2369/2542 [00:33<00:02, 71.72it/s, loss=0.57, v_num=1, val_loss=4.41, val_acc=0.0195]\n",
            "Epoch 0:  94% 2385/2542 [00:33<00:02, 71.92it/s, loss=0.57, v_num=1, val_loss=4.41, val_acc=0.0195]\n",
            "Epoch 0:  94% 2401/2542 [00:33<00:01, 72.12it/s, loss=0.57, v_num=1, val_loss=4.41, val_acc=0.0195]\n",
            "Validating:  72% 368/509 [00:02<00:01, 123.98it/s]\u001b[A\n",
            "Epoch 0:  95% 2417/2542 [00:33<00:01, 72.33it/s, loss=0.57, v_num=1, val_loss=4.41, val_acc=0.0195]\n",
            "Epoch 0:  96% 2433/2542 [00:33<00:01, 72.52it/s, loss=0.57, v_num=1, val_loss=4.41, val_acc=0.0195]\n",
            "Epoch 0:  96% 2449/2542 [00:33<00:01, 72.72it/s, loss=0.57, v_num=1, val_loss=4.41, val_acc=0.0195]\n",
            "Epoch 0:  97% 2465/2542 [00:33<00:01, 72.92it/s, loss=0.57, v_num=1, val_loss=4.41, val_acc=0.0195]\n",
            "Validating:  85% 433/509 [00:03<00:00, 123.69it/s]\u001b[A\n",
            "Epoch 0:  98% 2481/2542 [00:33<00:00, 73.11it/s, loss=0.57, v_num=1, val_loss=4.41, val_acc=0.0195]\n",
            "Epoch 0:  98% 2497/2542 [00:34<00:00, 73.30it/s, loss=0.57, v_num=1, val_loss=4.41, val_acc=0.0195]\n",
            "Epoch 0:  99% 2513/2542 [00:34<00:00, 73.49it/s, loss=0.57, v_num=1, val_loss=4.41, val_acc=0.0195]\n",
            "Epoch 0:  99% 2529/2542 [00:34<00:00, 73.67it/s, loss=0.57, v_num=1, val_loss=4.41, val_acc=0.0195]\n",
            "Epoch 0: 100% 2542/2542 [00:34<00:00, 73.66it/s, loss=0.57, v_num=1, val_loss=0.572, val_acc=0.789]\n",
            "Epoch 1:  80% 2033/2542 [00:30<00:07, 65.95it/s, loss=0.508, v_num=1, val_loss=0.572, val_acc=0.789]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/509 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 1:  81% 2048/2542 [00:31<00:07, 65.88it/s, loss=0.508, v_num=1, val_loss=0.572, val_acc=0.789]\n",
            "Epoch 1:  81% 2064/2542 [00:31<00:07, 66.11it/s, loss=0.508, v_num=1, val_loss=0.572, val_acc=0.789]\n",
            "Epoch 1:  82% 2080/2542 [00:31<00:06, 66.34it/s, loss=0.508, v_num=1, val_loss=0.572, val_acc=0.789]\n",
            "Epoch 1:  82% 2096/2542 [00:31<00:06, 66.57it/s, loss=0.508, v_num=1, val_loss=0.572, val_acc=0.789]\n",
            "Validating:  13% 64/509 [00:00<00:03, 122.44it/s]\u001b[A\n",
            "Epoch 1:  83% 2112/2542 [00:31<00:06, 66.79it/s, loss=0.508, v_num=1, val_loss=0.572, val_acc=0.789]\n",
            "Epoch 1:  84% 2128/2542 [00:31<00:06, 67.02it/s, loss=0.508, v_num=1, val_loss=0.572, val_acc=0.789]\n",
            "Epoch 1:  84% 2144/2542 [00:31<00:05, 67.27it/s, loss=0.508, v_num=1, val_loss=0.572, val_acc=0.789]\n",
            "Epoch 1:  85% 2160/2542 [00:31<00:05, 67.53it/s, loss=0.508, v_num=1, val_loss=0.572, val_acc=0.789]\n",
            "Epoch 1:  86% 2176/2542 [00:32<00:05, 67.79it/s, loss=0.508, v_num=1, val_loss=0.572, val_acc=0.789]\n",
            "Epoch 1:  86% 2192/2542 [00:32<00:05, 68.05it/s, loss=0.508, v_num=1, val_loss=0.572, val_acc=0.789]\n",
            "Epoch 1:  87% 2208/2542 [00:32<00:04, 68.32it/s, loss=0.508, v_num=1, val_loss=0.572, val_acc=0.789]\n",
            "Epoch 1:  87% 2224/2542 [00:32<00:04, 68.58it/s, loss=0.508, v_num=1, val_loss=0.572, val_acc=0.789]\n",
            "Validating:  38% 191/509 [00:01<00:02, 140.69it/s]\u001b[A\n",
            "Epoch 1:  88% 2240/2542 [00:32<00:04, 68.84it/s, loss=0.508, v_num=1, val_loss=0.572, val_acc=0.789]\n",
            "Epoch 1:  89% 2256/2542 [00:32<00:04, 69.10it/s, loss=0.508, v_num=1, val_loss=0.572, val_acc=0.789]\n",
            "Epoch 1:  89% 2272/2542 [00:32<00:03, 69.35it/s, loss=0.508, v_num=1, val_loss=0.572, val_acc=0.789]\n",
            "Epoch 1:  90% 2288/2542 [00:32<00:03, 69.61it/s, loss=0.508, v_num=1, val_loss=0.572, val_acc=0.789]\n",
            "Epoch 1:  91% 2304/2542 [00:32<00:03, 69.86it/s, loss=0.508, v_num=1, val_loss=0.572, val_acc=0.789]\n",
            "Epoch 1:  91% 2320/2542 [00:33<00:03, 70.10it/s, loss=0.508, v_num=1, val_loss=0.572, val_acc=0.789]\n",
            "Epoch 1:  92% 2336/2542 [00:33<00:02, 70.35it/s, loss=0.508, v_num=1, val_loss=0.572, val_acc=0.789]\n",
            "Epoch 1:  93% 2352/2542 [00:33<00:02, 70.59it/s, loss=0.508, v_num=1, val_loss=0.572, val_acc=0.789]\n",
            "Epoch 1:  93% 2368/2542 [00:33<00:02, 70.84it/s, loss=0.508, v_num=1, val_loss=0.572, val_acc=0.789]\n",
            "Epoch 1:  94% 2384/2542 [00:33<00:02, 71.08it/s, loss=0.508, v_num=1, val_loss=0.572, val_acc=0.789]\n",
            "Epoch 1:  94% 2400/2542 [00:33<00:01, 71.32it/s, loss=0.508, v_num=1, val_loss=0.572, val_acc=0.789]\n",
            "Epoch 1:  95% 2416/2542 [00:33<00:01, 71.55it/s, loss=0.508, v_num=1, val_loss=0.572, val_acc=0.789]\n",
            "Epoch 1:  96% 2432/2542 [00:33<00:01, 71.76it/s, loss=0.508, v_num=1, val_loss=0.572, val_acc=0.789]\n",
            "Epoch 1:  96% 2448/2542 [00:34<00:01, 71.94it/s, loss=0.508, v_num=1, val_loss=0.572, val_acc=0.789]\n",
            "Validating:  82% 415/509 [00:03<00:00, 129.16it/s]\u001b[A\n",
            "Epoch 1:  97% 2464/2542 [00:34<00:01, 72.12it/s, loss=0.508, v_num=1, val_loss=0.572, val_acc=0.789]\n",
            "Epoch 1:  98% 2480/2542 [00:34<00:00, 72.32it/s, loss=0.508, v_num=1, val_loss=0.572, val_acc=0.789]\n",
            "Epoch 1:  98% 2496/2542 [00:34<00:00, 72.49it/s, loss=0.508, v_num=1, val_loss=0.572, val_acc=0.789]\n",
            "Epoch 1:  99% 2512/2542 [00:34<00:00, 72.68it/s, loss=0.508, v_num=1, val_loss=0.572, val_acc=0.789]\n",
            "Validating:  94% 481/509 [00:03<00:00, 121.75it/s]\u001b[A\n",
            "Epoch 1:  99% 2528/2542 [00:34<00:00, 72.86it/s, loss=0.508, v_num=1, val_loss=0.572, val_acc=0.789]\n",
            "Epoch 1: 100% 2542/2542 [00:34<00:00, 72.85it/s, loss=0.508, v_num=1, val_loss=0.528, val_acc=0.798]\n",
            "Epoch 2:  80% 2033/2542 [00:31<00:07, 65.55it/s, loss=0.463, v_num=1, val_loss=0.528, val_acc=0.798]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/509 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 2:  81% 2048/2542 [00:31<00:07, 65.23it/s, loss=0.463, v_num=1, val_loss=0.528, val_acc=0.798]\n",
            "Epoch 2:  81% 2064/2542 [00:31<00:07, 65.45it/s, loss=0.463, v_num=1, val_loss=0.528, val_acc=0.798]\n",
            "Epoch 2:  82% 2080/2542 [00:31<00:07, 65.68it/s, loss=0.463, v_num=1, val_loss=0.528, val_acc=0.798]\n",
            "Validating:  10% 50/509 [00:00<00:03, 120.53it/s]\u001b[A\n",
            "Epoch 2:  82% 2096/2542 [00:31<00:06, 65.91it/s, loss=0.463, v_num=1, val_loss=0.528, val_acc=0.798]\n",
            "Epoch 2:  83% 2112/2542 [00:31<00:06, 66.14it/s, loss=0.463, v_num=1, val_loss=0.528, val_acc=0.798]\n",
            "Epoch 2:  84% 2128/2542 [00:32<00:06, 66.36it/s, loss=0.463, v_num=1, val_loss=0.528, val_acc=0.798]\n",
            "Epoch 2:  84% 2144/2542 [00:32<00:05, 66.62it/s, loss=0.463, v_num=1, val_loss=0.528, val_acc=0.798]\n",
            "Epoch 2:  85% 2160/2542 [00:32<00:05, 66.85it/s, loss=0.463, v_num=1, val_loss=0.528, val_acc=0.798]\n",
            "Validating:  25% 127/509 [00:01<00:03, 125.10it/s]\u001b[A\n",
            "Epoch 2:  86% 2176/2542 [00:32<00:05, 67.07it/s, loss=0.463, v_num=1, val_loss=0.528, val_acc=0.798]\n",
            "Epoch 2:  86% 2192/2542 [00:32<00:05, 67.28it/s, loss=0.463, v_num=1, val_loss=0.528, val_acc=0.798]\n",
            "Epoch 2:  87% 2208/2542 [00:32<00:04, 67.50it/s, loss=0.463, v_num=1, val_loss=0.528, val_acc=0.798]\n",
            "Epoch 2:  87% 2224/2542 [00:32<00:04, 67.72it/s, loss=0.463, v_num=1, val_loss=0.528, val_acc=0.798]\n",
            "Validating:  38% 192/509 [00:01<00:02, 121.51it/s]\u001b[A\n",
            "Epoch 2:  88% 2240/2542 [00:32<00:04, 67.94it/s, loss=0.463, v_num=1, val_loss=0.528, val_acc=0.798]\n",
            "Epoch 2:  89% 2256/2542 [00:33<00:04, 68.18it/s, loss=0.463, v_num=1, val_loss=0.528, val_acc=0.798]\n",
            "Epoch 2:  89% 2272/2542 [00:33<00:03, 68.43it/s, loss=0.463, v_num=1, val_loss=0.528, val_acc=0.798]\n",
            "Epoch 2:  90% 2288/2542 [00:33<00:03, 68.68it/s, loss=0.463, v_num=1, val_loss=0.528, val_acc=0.798]\n",
            "Epoch 2:  91% 2304/2542 [00:33<00:03, 68.93it/s, loss=0.463, v_num=1, val_loss=0.528, val_acc=0.798]\n",
            "Epoch 2:  91% 2320/2542 [00:33<00:03, 69.17it/s, loss=0.463, v_num=1, val_loss=0.528, val_acc=0.798]\n",
            "Epoch 2:  92% 2336/2542 [00:33<00:02, 69.42it/s, loss=0.463, v_num=1, val_loss=0.528, val_acc=0.798]\n",
            "Epoch 2:  93% 2352/2542 [00:33<00:02, 69.66it/s, loss=0.463, v_num=1, val_loss=0.528, val_acc=0.798]\n",
            "Epoch 2:  93% 2368/2542 [00:33<00:02, 69.91it/s, loss=0.463, v_num=1, val_loss=0.528, val_acc=0.798]\n",
            "Epoch 2:  94% 2384/2542 [00:33<00:02, 70.15it/s, loss=0.463, v_num=1, val_loss=0.528, val_acc=0.798]\n",
            "Epoch 2:  94% 2400/2542 [00:34<00:02, 70.39it/s, loss=0.463, v_num=1, val_loss=0.528, val_acc=0.798]\n",
            "Epoch 2:  95% 2416/2542 [00:34<00:01, 70.63it/s, loss=0.463, v_num=1, val_loss=0.528, val_acc=0.798]\n",
            "Validating:  75% 383/509 [00:02<00:00, 143.02it/s]\u001b[A\n",
            "Epoch 2:  96% 2432/2542 [00:34<00:01, 70.86it/s, loss=0.463, v_num=1, val_loss=0.528, val_acc=0.798]\n",
            "Epoch 2:  96% 2448/2542 [00:34<00:01, 71.10it/s, loss=0.463, v_num=1, val_loss=0.528, val_acc=0.798]\n",
            "Epoch 2:  97% 2464/2542 [00:34<00:01, 71.33it/s, loss=0.463, v_num=1, val_loss=0.528, val_acc=0.798]\n",
            "Epoch 2:  98% 2480/2542 [00:34<00:00, 71.56it/s, loss=0.463, v_num=1, val_loss=0.528, val_acc=0.798]\n",
            "Epoch 2:  98% 2496/2542 [00:34<00:00, 71.79it/s, loss=0.463, v_num=1, val_loss=0.528, val_acc=0.798]\n",
            "Epoch 2:  99% 2512/2542 [00:34<00:00, 72.02it/s, loss=0.463, v_num=1, val_loss=0.528, val_acc=0.798]\n",
            "Epoch 2:  99% 2528/2542 [00:34<00:00, 72.24it/s, loss=0.463, v_num=1, val_loss=0.528, val_acc=0.798]\n",
            "Epoch 2: 100% 2542/2542 [00:35<00:00, 72.29it/s, loss=0.463, v_num=1, val_loss=0.509, val_acc=0.805]\n",
            "Epoch 3:  80% 2033/2542 [00:31<00:07, 65.41it/s, loss=0.437, v_num=1, val_loss=0.509, val_acc=0.805]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Epoch 3:  81% 2048/2542 [00:31<00:07, 65.36it/s, loss=0.437, v_num=1, val_loss=0.509, val_acc=0.805]\n",
            "Validating:   3% 15/509 [00:00<00:03, 145.45it/s]\u001b[A\n",
            "Epoch 3:  81% 2064/2542 [00:31<00:07, 65.64it/s, loss=0.437, v_num=1, val_loss=0.509, val_acc=0.805]\n",
            "Epoch 3:  82% 2080/2542 [00:31<00:07, 65.89it/s, loss=0.437, v_num=1, val_loss=0.509, val_acc=0.805]\n",
            "Epoch 3:  82% 2096/2542 [00:31<00:06, 66.14it/s, loss=0.437, v_num=1, val_loss=0.509, val_acc=0.805]\n",
            "Epoch 3:  83% 2112/2542 [00:31<00:06, 66.40it/s, loss=0.437, v_num=1, val_loss=0.509, val_acc=0.805]\n",
            "Epoch 3:  84% 2128/2542 [00:31<00:06, 66.67it/s, loss=0.437, v_num=1, val_loss=0.509, val_acc=0.805]\n",
            "Epoch 3:  84% 2144/2542 [00:32<00:05, 66.94it/s, loss=0.437, v_num=1, val_loss=0.509, val_acc=0.805]\n",
            "Epoch 3:  85% 2160/2542 [00:32<00:05, 67.21it/s, loss=0.437, v_num=1, val_loss=0.509, val_acc=0.805]\n",
            "Epoch 3:  86% 2176/2542 [00:32<00:05, 67.47it/s, loss=0.437, v_num=1, val_loss=0.509, val_acc=0.805]\n",
            "Epoch 3:  86% 2192/2542 [00:32<00:05, 67.73it/s, loss=0.437, v_num=1, val_loss=0.509, val_acc=0.805]\n",
            "Epoch 3:  87% 2208/2542 [00:32<00:04, 67.99it/s, loss=0.437, v_num=1, val_loss=0.509, val_acc=0.805]\n",
            "Validating:  34% 175/509 [00:01<00:02, 142.25it/s]\u001b[A\n",
            "Epoch 3:  87% 2224/2542 [00:32<00:04, 68.25it/s, loss=0.437, v_num=1, val_loss=0.509, val_acc=0.805]\n",
            "Epoch 3:  88% 2240/2542 [00:32<00:04, 68.51it/s, loss=0.437, v_num=1, val_loss=0.509, val_acc=0.805]\n",
            "Epoch 3:  89% 2256/2542 [00:32<00:04, 68.71it/s, loss=0.437, v_num=1, val_loss=0.509, val_acc=0.805]\n",
            "Epoch 3:  89% 2272/2542 [00:32<00:03, 68.94it/s, loss=0.437, v_num=1, val_loss=0.509, val_acc=0.805]\n",
            "Epoch 3:  90% 2288/2542 [00:33<00:03, 69.18it/s, loss=0.437, v_num=1, val_loss=0.509, val_acc=0.805]\n",
            "Epoch 3:  91% 2304/2542 [00:33<00:03, 69.41it/s, loss=0.437, v_num=1, val_loss=0.509, val_acc=0.805]\n",
            "Epoch 3:  91% 2320/2542 [00:33<00:03, 69.64it/s, loss=0.437, v_num=1, val_loss=0.509, val_acc=0.805]\n",
            "Epoch 3:  92% 2336/2542 [00:33<00:02, 69.89it/s, loss=0.437, v_num=1, val_loss=0.509, val_acc=0.805]\n",
            "Epoch 3:  93% 2352/2542 [00:33<00:02, 70.13it/s, loss=0.437, v_num=1, val_loss=0.509, val_acc=0.805]\n",
            "Epoch 3:  93% 2368/2542 [00:33<00:02, 70.37it/s, loss=0.437, v_num=1, val_loss=0.509, val_acc=0.805]\n",
            "Validating:  66% 335/509 [00:02<00:01, 138.51it/s]\u001b[A\n",
            "Epoch 3:  94% 2384/2542 [00:33<00:02, 70.60it/s, loss=0.437, v_num=1, val_loss=0.509, val_acc=0.805]\n",
            "Epoch 3:  94% 2400/2542 [00:33<00:02, 70.83it/s, loss=0.437, v_num=1, val_loss=0.509, val_acc=0.805]\n",
            "Epoch 3:  95% 2416/2542 [00:34<00:01, 71.04it/s, loss=0.437, v_num=1, val_loss=0.509, val_acc=0.805]\n",
            "Epoch 3:  96% 2432/2542 [00:34<00:01, 71.24it/s, loss=0.437, v_num=1, val_loss=0.509, val_acc=0.805]\n",
            "Epoch 3:  96% 2448/2542 [00:34<00:01, 71.48it/s, loss=0.437, v_num=1, val_loss=0.509, val_acc=0.805]\n",
            "Epoch 3:  97% 2464/2542 [00:34<00:01, 71.71it/s, loss=0.437, v_num=1, val_loss=0.509, val_acc=0.805]\n",
            "Epoch 3:  98% 2480/2542 [00:34<00:00, 71.94it/s, loss=0.437, v_num=1, val_loss=0.509, val_acc=0.805]\n",
            "Epoch 3:  98% 2496/2542 [00:34<00:00, 72.17it/s, loss=0.437, v_num=1, val_loss=0.509, val_acc=0.805]\n",
            "Epoch 3:  99% 2512/2542 [00:34<00:00, 72.40it/s, loss=0.437, v_num=1, val_loss=0.509, val_acc=0.805]\n",
            "Validating:  94% 479/509 [00:03<00:00, 141.91it/s]\u001b[A\n",
            "Epoch 3:  99% 2528/2542 [00:34<00:00, 72.63it/s, loss=0.437, v_num=1, val_loss=0.509, val_acc=0.805]\n",
            "Epoch 3: 100% 2542/2542 [00:34<00:00, 72.65it/s, loss=0.437, v_num=1, val_loss=0.498, val_acc=0.807]\n",
            "Epoch 4:  80% 2033/2542 [00:31<00:07, 65.42it/s, loss=0.408, v_num=1, val_loss=0.498, val_acc=0.807]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Epoch 4:  81% 2048/2542 [00:31<00:07, 65.36it/s, loss=0.408, v_num=1, val_loss=0.498, val_acc=0.807]\n",
            "Validating:   3% 15/509 [00:00<00:03, 142.13it/s]\u001b[A\n",
            "Epoch 4:  81% 2064/2542 [00:31<00:07, 65.63it/s, loss=0.408, v_num=1, val_loss=0.498, val_acc=0.807]\n",
            "Epoch 4:  82% 2080/2542 [00:31<00:07, 65.91it/s, loss=0.408, v_num=1, val_loss=0.498, val_acc=0.807]\n",
            "Epoch 4:  82% 2096/2542 [00:31<00:06, 66.18it/s, loss=0.408, v_num=1, val_loss=0.498, val_acc=0.807]\n",
            "Epoch 4:  83% 2112/2542 [00:31<00:06, 66.46it/s, loss=0.408, v_num=1, val_loss=0.498, val_acc=0.807]\n",
            "Epoch 4:  84% 2128/2542 [00:31<00:06, 66.69it/s, loss=0.408, v_num=1, val_loss=0.498, val_acc=0.807]\n",
            "Epoch 4:  84% 2144/2542 [00:32<00:05, 66.92it/s, loss=0.408, v_num=1, val_loss=0.498, val_acc=0.807]\n",
            "Epoch 4:  85% 2160/2542 [00:32<00:05, 67.18it/s, loss=0.408, v_num=1, val_loss=0.498, val_acc=0.807]\n",
            "Epoch 4:  86% 2176/2542 [00:32<00:05, 67.44it/s, loss=0.408, v_num=1, val_loss=0.498, val_acc=0.807]\n",
            "Epoch 4:  86% 2192/2542 [00:32<00:05, 67.70it/s, loss=0.408, v_num=1, val_loss=0.498, val_acc=0.807]\n",
            "Validating:  31% 159/509 [00:01<00:02, 139.30it/s]\u001b[A\n",
            "Epoch 4:  87% 2208/2542 [00:32<00:04, 67.96it/s, loss=0.408, v_num=1, val_loss=0.498, val_acc=0.807]\n",
            "Epoch 4:  87% 2224/2542 [00:32<00:04, 68.22it/s, loss=0.408, v_num=1, val_loss=0.498, val_acc=0.807]\n",
            "Epoch 4:  88% 2240/2542 [00:32<00:04, 68.48it/s, loss=0.408, v_num=1, val_loss=0.498, val_acc=0.807]\n",
            "Epoch 4:  89% 2256/2542 [00:32<00:04, 68.70it/s, loss=0.408, v_num=1, val_loss=0.498, val_acc=0.807]\n",
            "Epoch 4:  89% 2272/2542 [00:32<00:03, 68.93it/s, loss=0.408, v_num=1, val_loss=0.498, val_acc=0.807]\n",
            "Epoch 4:  90% 2288/2542 [00:33<00:03, 69.18it/s, loss=0.408, v_num=1, val_loss=0.498, val_acc=0.807]\n",
            "Epoch 4:  91% 2304/2542 [00:33<00:03, 69.43it/s, loss=0.408, v_num=1, val_loss=0.498, val_acc=0.807]\n",
            "Epoch 4:  91% 2320/2542 [00:33<00:03, 69.68it/s, loss=0.408, v_num=1, val_loss=0.498, val_acc=0.807]\n",
            "Epoch 4:  92% 2336/2542 [00:33<00:02, 69.92it/s, loss=0.408, v_num=1, val_loss=0.498, val_acc=0.807]\n",
            "Epoch 4:  93% 2352/2542 [00:33<00:02, 70.17it/s, loss=0.408, v_num=1, val_loss=0.498, val_acc=0.807]\n",
            "Epoch 4:  93% 2368/2542 [00:33<00:02, 70.41it/s, loss=0.408, v_num=1, val_loss=0.498, val_acc=0.807]\n",
            "Epoch 4:  94% 2384/2542 [00:33<00:02, 70.66it/s, loss=0.408, v_num=1, val_loss=0.498, val_acc=0.807]\n",
            "Epoch 4:  94% 2400/2542 [00:33<00:02, 70.90it/s, loss=0.408, v_num=1, val_loss=0.498, val_acc=0.807]\n",
            "Epoch 4:  95% 2416/2542 [00:33<00:01, 71.14it/s, loss=0.408, v_num=1, val_loss=0.498, val_acc=0.807]\n",
            "Validating:  75% 383/509 [00:02<00:00, 142.71it/s]\u001b[A\n",
            "Epoch 4:  96% 2432/2542 [00:34<00:01, 71.34it/s, loss=0.408, v_num=1, val_loss=0.498, val_acc=0.807]\n",
            "Epoch 4:  96% 2448/2542 [00:34<00:01, 71.53it/s, loss=0.408, v_num=1, val_loss=0.498, val_acc=0.807]\n",
            "Epoch 4:  97% 2464/2542 [00:34<00:01, 71.72it/s, loss=0.408, v_num=1, val_loss=0.498, val_acc=0.807]\n",
            "Epoch 4:  98% 2480/2542 [00:34<00:00, 71.90it/s, loss=0.408, v_num=1, val_loss=0.498, val_acc=0.807]\n",
            "Epoch 4:  98% 2496/2542 [00:34<00:00, 72.08it/s, loss=0.408, v_num=1, val_loss=0.498, val_acc=0.807]\n",
            "Validating:  91% 465/509 [00:03<00:00, 121.83it/s]\u001b[A\n",
            "Epoch 4:  99% 2512/2542 [00:34<00:00, 72.26it/s, loss=0.408, v_num=1, val_loss=0.498, val_acc=0.807]\n",
            "Epoch 4:  99% 2528/2542 [00:34<00:00, 72.48it/s, loss=0.408, v_num=1, val_loss=0.498, val_acc=0.807]\n",
            "Epoch 4: 100% 2542/2542 [00:34<00:00, 72.65it/s, loss=0.408, v_num=1, val_loss=0.505, val_acc=0.807]\n",
            "Epoch 4: 100% 2542/2542 [00:34<00:00, 72.65it/s, loss=0.408, v_num=1, val_loss=0.505, val_acc=0.807]\n",
            "Testing: 100% 422/422 [00:02<00:00, 143.94it/s]\n",
            "--------------------------------------------------------------------------------\n",
            "DATALOADER:0 TEST RESULTS\n",
            "{'test_acc': 0.8061420917510986}\n",
            "--------------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Me8Af-UF-pEd",
        "outputId": "901ca4e1-c873-4a5e-f8f2-3aa65415eb10"
      },
      "source": [
        "!python3 training/run_experiment.py --model_class=CNN --data_class=EMNIST --max_epochs=50 --gpus=1 --overfit_batches=2"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/pytorch_lightning/utilities/distributed.py:50: UserWarning: You have set progress_bar_refresh_rate < 20 on Google Colab. This may crash. Consider using progress_bar_refresh_rate >= 20 in Trainer.\n",
            "  warnings.warn(*args, **kwargs)\n",
            "GPU available: True, used: True\n",
            "TPU available: None, using: 0 TPU cores\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "2021-02-13 19:58:48.570534: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
            "\n",
            "   | Name             | Type      | Params\n",
            "------------------------------------------------\n",
            "0  | model            | CNN       | 1.7 M \n",
            "1  | model.conv1      | ConvBlock | 640   \n",
            "2  | model.conv1.conv | Conv2d    | 640   \n",
            "3  | model.conv1.relu | ReLU      | 0     \n",
            "4  | model.conv2      | ConvBlock | 36.9 K\n",
            "5  | model.conv2.conv | Conv2d    | 36.9 K\n",
            "6  | model.conv2.relu | ReLU      | 0     \n",
            "7  | model.dropout    | Dropout   | 0     \n",
            "8  | model.max_pool   | MaxPool2d | 0     \n",
            "9  | model.fc1        | Linear    | 1.6 M \n",
            "10 | model.fc2        | Linear    | 10.7 K\n",
            "11 | train_acc        | Accuracy  | 0     \n",
            "12 | val_acc          | Accuracy  | 0     \n",
            "13 | test_acc         | Accuracy  | 0     \n",
            "------------------------------------------------\n",
            "1.7 M     Trainable params\n",
            "0         Non-trainable params\n",
            "1.7 M     Total params\n",
            "Epoch 0:  50% 2/4 [00:00<00:00, 46.13it/s, loss=4.4, v_num=2, val_loss=4.42, val_acc=0.00391] \n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Epoch 0: 100% 4/4 [00:00<00:00, 25.67it/s, loss=4.4, v_num=2, val_loss=4.21, val_acc=0.0703] \n",
            "Epoch 1:  50% 2/4 [00:00<00:00, 44.90it/s, loss=4.28, v_num=2, val_loss=4.21, val_acc=0.0703]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Epoch 1: 100% 4/4 [00:00<00:00, 27.80it/s, loss=4.28, v_num=2, val_loss=3.91, val_acc=0.0469]\n",
            "Epoch 2:  50% 2/4 [00:00<00:00, 45.72it/s, loss=4.13, v_num=2, val_loss=3.91, val_acc=0.0469]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Epoch 2: 100% 4/4 [00:00<00:00, 31.02it/s, loss=4.13, v_num=2, val_loss=3.5, val_acc=0.281]  \n",
            "Epoch 3:  50% 2/4 [00:00<00:00, 47.72it/s, loss=3.95, v_num=2, val_loss=3.5, val_acc=0.281]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Epoch 3: 100% 4/4 [00:00<00:00, 28.08it/s, loss=3.95, v_num=2, val_loss=3.04, val_acc=0.328]\n",
            "Epoch 4:  50% 2/4 [00:00<00:00, 48.82it/s, loss=3.75, v_num=2, val_loss=3.04, val_acc=0.328]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Epoch 4: 100% 4/4 [00:00<00:00, 29.84it/s, loss=3.75, v_num=2, val_loss=2.53, val_acc=0.449]\n",
            "Epoch 5:  50% 2/4 [00:00<00:00, 49.31it/s, loss=3.53, v_num=2, val_loss=2.53, val_acc=0.449]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Epoch 5: 100% 4/4 [00:00<00:00, 30.75it/s, loss=3.53, v_num=2, val_loss=2.04, val_acc=0.547]\n",
            "Epoch 6:  50% 2/4 [00:00<00:00, 49.59it/s, loss=3.3, v_num=2, val_loss=2.04, val_acc=0.547] \n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Epoch 6: 100% 4/4 [00:00<00:00, 31.33it/s, loss=3.3, v_num=2, val_loss=1.61, val_acc=0.656]\n",
            "Epoch 7:  50% 2/4 [00:00<00:00, 49.62it/s, loss=3.08, v_num=2, val_loss=1.61, val_acc=0.656]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Epoch 7: 100% 4/4 [00:00<00:00, 30.60it/s, loss=3.08, v_num=2, val_loss=1.23, val_acc=0.711]\n",
            "Epoch 8:  50% 2/4 [00:00<00:00, 49.82it/s, loss=2.87, v_num=2, val_loss=1.23, val_acc=0.711]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Epoch 8: 100% 4/4 [00:00<00:00, 31.52it/s, loss=2.87, v_num=2, val_loss=0.91, val_acc=0.785]\n",
            "Epoch 9:  50% 2/4 [00:00<00:00, 49.20it/s, loss=2.67, v_num=2, val_loss=0.91, val_acc=0.785]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Epoch 9: 100% 4/4 [00:00<00:00, 30.76it/s, loss=2.67, v_num=2, val_loss=0.653, val_acc=0.844]\n",
            "Epoch 10:  50% 2/4 [00:00<00:00, 43.02it/s, loss=2.29, v_num=2, val_loss=0.653, val_acc=0.844]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Epoch 10: 100% 4/4 [00:00<00:00, 27.84it/s, loss=2.29, v_num=2, val_loss=0.43, val_acc=0.922] \n",
            "Epoch 11:  50% 2/4 [00:00<00:00, 44.64it/s, loss=1.91, v_num=2, val_loss=0.43, val_acc=0.922]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Epoch 11: 100% 4/4 [00:00<00:00, 28.91it/s, loss=1.91, v_num=2, val_loss=0.279, val_acc=0.938]\n",
            "Epoch 12:  50% 2/4 [00:00<00:00, 43.67it/s, loss=1.56, v_num=2, val_loss=0.279, val_acc=0.938]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Epoch 12: 100% 4/4 [00:00<00:00, 28.41it/s, loss=1.56, v_num=2, val_loss=0.168, val_acc=0.98] \n",
            "Epoch 13:  50% 2/4 [00:00<00:00, 44.73it/s, loss=1.23, v_num=2, val_loss=0.168, val_acc=0.98]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Epoch 13: 100% 4/4 [00:00<00:00, 29.11it/s, loss=1.23, v_num=2, val_loss=0.105, val_acc=0.988]\n",
            "Epoch 14:  50% 2/4 [00:00<00:00, 42.36it/s, loss=0.952, v_num=2, val_loss=0.105, val_acc=0.988]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Epoch 14: 100% 4/4 [00:00<00:00, 27.80it/s, loss=0.952, v_num=2, val_loss=0.0691, val_acc=0.996]\n",
            "Epoch 15:  50% 2/4 [00:00<00:00, 44.49it/s, loss=0.716, v_num=2, val_loss=0.0691, val_acc=0.996]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Epoch 15: 100% 4/4 [00:00<00:00, 29.15it/s, loss=0.716, v_num=2, val_loss=0.0411, val_acc=0.996]\n",
            "Epoch 16:  50% 2/4 [00:00<00:00, 49.77it/s, loss=0.525, v_num=2, val_loss=0.0411, val_acc=0.996]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Epoch 16: 100% 4/4 [00:00<00:00, 31.12it/s, loss=0.525, v_num=2, val_loss=0.028, val_acc=0.996] \n",
            "Epoch 17:  50% 2/4 [00:00<00:00, 44.56it/s, loss=0.374, v_num=2, val_loss=0.028, val_acc=0.996]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Epoch 17: 100% 4/4 [00:00<00:00, 28.93it/s, loss=0.374, v_num=2, val_loss=0.0189, val_acc=1]   \n",
            "Epoch 18:  50% 2/4 [00:00<00:00, 43.51it/s, loss=0.26, v_num=2, val_loss=0.0189, val_acc=1] \n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Epoch 18: 100% 4/4 [00:00<00:00, 28.12it/s, loss=0.26, v_num=2, val_loss=0.0163, val_acc=1]\n",
            "Epoch 19:  50% 2/4 [00:00<00:00, 44.97it/s, loss=0.177, v_num=2, val_loss=0.0163, val_acc=1]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Epoch 19: 100% 4/4 [00:00<00:00, 29.30it/s, loss=0.177, v_num=2, val_loss=0.0127, val_acc=1]\n",
            "Epoch 20:  50% 2/4 [00:00<00:00, 44.45it/s, loss=0.116, v_num=2, val_loss=0.0127, val_acc=1]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Epoch 20: 100% 4/4 [00:00<00:00, 28.02it/s, loss=0.116, v_num=2, val_loss=0.0112, val_acc=1]\n",
            "Epoch 21:  50% 2/4 [00:00<00:00, 43.00it/s, loss=0.0761, v_num=2, val_loss=0.0112, val_acc=1]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Epoch 21: 100% 4/4 [00:00<00:00, 54.04it/s, loss=0.0761, v_num=2, val_loss=0.0147, val_acc=0.996]\n",
            "Epoch 22:  50% 2/4 [00:00<00:00, 46.22it/s, loss=0.0511, v_num=2, val_loss=0.0147, val_acc=0.996]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Epoch 22: 100% 4/4 [00:00<00:00, 57.00it/s, loss=0.0511, v_num=2, val_loss=0.0184, val_acc=0.996]\n",
            "Epoch 23:  50% 2/4 [00:00<00:00, 51.13it/s, loss=0.0385, v_num=2, val_loss=0.0184, val_acc=0.996]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Epoch 23: 100% 4/4 [00:00<00:00, 63.86it/s, loss=0.0385, v_num=2, val_loss=0.0168, val_acc=0.996]\n",
            "Epoch 24:  50% 2/4 [00:00<00:00, 52.02it/s, loss=0.0289, v_num=2, val_loss=0.0168, val_acc=0.996]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Epoch 24: 100% 4/4 [00:00<00:00, 31.14it/s, loss=0.0289, v_num=2, val_loss=0.00791, val_acc=0.996]\n",
            "Epoch 25:  50% 2/4 [00:00<00:00, 45.96it/s, loss=0.0232, v_num=2, val_loss=0.00791, val_acc=0.996]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Epoch 25: 100% 4/4 [00:00<00:00, 56.98it/s, loss=0.0232, v_num=2, val_loss=0.00826, val_acc=1]    \n",
            "Epoch 26:  50% 2/4 [00:00<00:00, 47.18it/s, loss=0.0204, v_num=2, val_loss=0.00826, val_acc=1]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Epoch 26: 100% 4/4 [00:00<00:00, 57.86it/s, loss=0.0204, v_num=2, val_loss=0.0289, val_acc=0.992]\n",
            "Epoch 27:  50% 2/4 [00:00<00:00, 46.06it/s, loss=0.0188, v_num=2, val_loss=0.0289, val_acc=0.992]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Epoch 27: 100% 4/4 [00:00<00:00, 56.23it/s, loss=0.0188, v_num=2, val_loss=0.00807, val_acc=0.996]\n",
            "Epoch 28:  50% 2/4 [00:00<00:00, 45.46it/s, loss=0.0183, v_num=2, val_loss=0.00807, val_acc=0.996]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Epoch 28: 100% 4/4 [00:00<00:00, 54.51it/s, loss=0.0183, v_num=2, val_loss=0.0263, val_acc=0.988] \n",
            "Epoch 29:  50% 2/4 [00:00<00:00, 50.34it/s, loss=0.0186, v_num=2, val_loss=0.0263, val_acc=0.988]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Epoch 29: 100% 4/4 [00:00<00:00, 30.46it/s, loss=0.0186, v_num=2, val_loss=0.00253, val_acc=1]   \n",
            "Epoch 30:  50% 2/4 [00:00<00:00, 47.36it/s, loss=0.018, v_num=2, val_loss=0.00253, val_acc=1] \n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Epoch 30: 100% 4/4 [00:00<00:00, 57.74it/s, loss=0.018, v_num=2, val_loss=0.0191, val_acc=0.992]\n",
            "Epoch 31:  50% 2/4 [00:00<00:00, 48.99it/s, loss=0.0185, v_num=2, val_loss=0.0191, val_acc=0.992]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Epoch 31: 100% 4/4 [00:00<00:00, 28.21it/s, loss=0.0185, v_num=2, val_loss=0.00182, val_acc=1]   \n",
            "Epoch 32:  50% 2/4 [00:00<00:00, 47.93it/s, loss=0.0176, v_num=2, val_loss=0.00182, val_acc=1]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Epoch 32: 100% 4/4 [00:00<00:00, 59.06it/s, loss=0.0176, v_num=2, val_loss=0.00494, val_acc=1]\n",
            "Epoch 33:  50% 2/4 [00:00<00:00, 49.82it/s, loss=0.0139, v_num=2, val_loss=0.00494, val_acc=1]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Epoch 33: 100% 4/4 [00:00<00:00, 28.51it/s, loss=0.0139, v_num=2, val_loss=0.00108, val_acc=1]\n",
            "Epoch 34:  50% 2/4 [00:00<00:00, 48.33it/s, loss=0.0129, v_num=2, val_loss=0.00108, val_acc=1]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Epoch 34: 100% 4/4 [00:00<00:00, 59.41it/s, loss=0.0129, v_num=2, val_loss=0.00272, val_acc=1]\n",
            "Epoch 35:  50% 2/4 [00:00<00:00, 50.29it/s, loss=0.0121, v_num=2, val_loss=0.00272, val_acc=1]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Epoch 35: 100% 4/4 [00:00<00:00, 61.34it/s, loss=0.0121, v_num=2, val_loss=0.0115, val_acc=0.992]\n",
            "Epoch 36:  50% 2/4 [00:00<00:00, 50.42it/s, loss=0.0118, v_num=2, val_loss=0.0115, val_acc=0.992]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Epoch 36: 100% 4/4 [00:00<00:00, 61.21it/s, loss=0.0118, v_num=2, val_loss=0.00155, val_acc=1]   \n",
            "Epoch 37:  50% 2/4 [00:00<00:00, 49.97it/s, loss=0.0104, v_num=2, val_loss=0.00155, val_acc=1]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Epoch 37: 100% 4/4 [00:00<00:00, 61.56it/s, loss=0.0104, v_num=2, val_loss=0.00276, val_acc=1]\n",
            "Epoch 38:  50% 2/4 [00:00<00:00, 49.40it/s, loss=0.0105, v_num=2, val_loss=0.00276, val_acc=1] \n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Epoch 38: 100% 4/4 [00:00<00:00, 60.51it/s, loss=0.0105, v_num=2, val_loss=0.00132, val_acc=1]\n",
            "Epoch 39:  50% 2/4 [00:00<00:00, 50.29it/s, loss=0.00861, v_num=2, val_loss=0.00132, val_acc=1]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Epoch 39: 100% 4/4 [00:00<00:00, 61.33it/s, loss=0.00861, v_num=2, val_loss=0.00845, val_acc=1]\n",
            "Epoch 40:  50% 2/4 [00:00<00:00, 51.43it/s, loss=0.0113, v_num=2, val_loss=0.00845, val_acc=1] \n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Epoch 40: 100% 4/4 [00:00<00:00, 62.20it/s, loss=0.0113, v_num=2, val_loss=0.00147, val_acc=1]\n",
            "Epoch 41:  50% 2/4 [00:00<00:00, 53.78it/s, loss=0.0101, v_num=2, val_loss=0.00147, val_acc=1]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Epoch 41: 100% 4/4 [00:00<00:00, 64.36it/s, loss=0.0101, v_num=2, val_loss=0.00218, val_acc=1]\n",
            "Epoch 42:  50% 2/4 [00:00<00:00, 54.05it/s, loss=0.0109, v_num=2, val_loss=0.00218, val_acc=1]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Epoch 42: 100% 4/4 [00:00<00:00, 60.13it/s, loss=0.0109, v_num=2, val_loss=0.0155, val_acc=0.996]\n",
            "Epoch 43:  50% 2/4 [00:00<00:00, 54.14it/s, loss=0.0115, v_num=2, val_loss=0.0155, val_acc=0.996]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Epoch 43: 100% 4/4 [00:00<00:00, 65.19it/s, loss=0.0115, v_num=2, val_loss=0.00267, val_acc=1]   \n",
            "Epoch 43: 100% 4/4 [00:00<00:00, 64.03it/s, loss=0.0115, v_num=2, val_loss=0.00267, val_acc=1]\n",
            "Testing: 100% 2/2 [00:00<00:00, 106.75it/s]\n",
            "--------------------------------------------------------------------------------\n",
            "DATALOADER:0 TEST RESULTS\n",
            "{'test_acc': 1.0}\n",
            "--------------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PDonzPlj-1Rm",
        "outputId": "c0640dd4-2de0-456c-92d1-f43bc86ef488"
      },
      "source": [
        "!python3 training/run_experiment.py --model_class=CNN --data_class=EMNIST --max_epochs=5 --gpus=1 --num_workers=4"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/pytorch_lightning/utilities/distributed.py:50: UserWarning: You have set progress_bar_refresh_rate < 20 on Google Colab. This may crash. Consider using progress_bar_refresh_rate >= 20 in Trainer.\n",
            "  warnings.warn(*args, **kwargs)\n",
            "GPU available: True, used: True\n",
            "TPU available: None, using: 0 TPU cores\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "2021-02-13 19:59:41.539728: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
            "\n",
            "   | Name             | Type      | Params\n",
            "------------------------------------------------\n",
            "0  | model            | CNN       | 1.7 M \n",
            "1  | model.conv1      | ConvBlock | 640   \n",
            "2  | model.conv1.conv | Conv2d    | 640   \n",
            "3  | model.conv1.relu | ReLU      | 0     \n",
            "4  | model.conv2      | ConvBlock | 36.9 K\n",
            "5  | model.conv2.conv | Conv2d    | 36.9 K\n",
            "6  | model.conv2.relu | ReLU      | 0     \n",
            "7  | model.dropout    | Dropout   | 0     \n",
            "8  | model.max_pool   | MaxPool2d | 0     \n",
            "9  | model.fc1        | Linear    | 1.6 M \n",
            "10 | model.fc2        | Linear    | 10.7 K\n",
            "11 | train_acc        | Accuracy  | 0     \n",
            "12 | val_acc          | Accuracy  | 0     \n",
            "13 | test_acc         | Accuracy  | 0     \n",
            "------------------------------------------------\n",
            "1.7 M     Trainable params\n",
            "0         Non-trainable params\n",
            "1.7 M     Total params\n",
            "Epoch 0:  80% 2033/2542 [00:25<00:06, 79.08it/s, loss=0.57, v_num=3, val_loss=4.41, val_acc=0.0195] \n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/509 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 0:  80% 2036/2542 [00:26<00:06, 78.14it/s, loss=0.57, v_num=3, val_loss=4.41, val_acc=0.0195]\n",
            "Epoch 0:  81% 2049/2542 [00:26<00:06, 78.33it/s, loss=0.57, v_num=3, val_loss=4.41, val_acc=0.0195]\n",
            "Epoch 0:  81% 2064/2542 [00:26<00:06, 78.57it/s, loss=0.57, v_num=3, val_loss=4.41, val_acc=0.0195]\n",
            "Epoch 0:  82% 2079/2542 [00:26<00:05, 78.82it/s, loss=0.57, v_num=3, val_loss=4.41, val_acc=0.0195]\n",
            "Epoch 0:  82% 2094/2542 [00:26<00:05, 79.04it/s, loss=0.57, v_num=3, val_loss=4.41, val_acc=0.0195]\n",
            "Epoch 0:  83% 2110/2542 [00:26<00:05, 79.31it/s, loss=0.57, v_num=3, val_loss=4.41, val_acc=0.0195]\n",
            "Epoch 0:  84% 2126/2542 [00:26<00:05, 79.55it/s, loss=0.57, v_num=3, val_loss=4.41, val_acc=0.0195]\n",
            "Epoch 0:  84% 2142/2542 [00:26<00:05, 79.81it/s, loss=0.57, v_num=3, val_loss=4.41, val_acc=0.0195]\n",
            "Epoch 0:  85% 2158/2542 [00:26<00:04, 80.05it/s, loss=0.57, v_num=3, val_loss=4.41, val_acc=0.0195]\n",
            "Epoch 0:  86% 2174/2542 [00:27<00:04, 80.30it/s, loss=0.57, v_num=3, val_loss=4.41, val_acc=0.0195]\n",
            "Validating:  28% 142/509 [00:01<00:04, 91.67it/s]\u001b[A\n",
            "Epoch 0:  86% 2190/2542 [00:27<00:04, 80.55it/s, loss=0.57, v_num=3, val_loss=4.41, val_acc=0.0195]\n",
            "Epoch 0:  87% 2206/2542 [00:27<00:04, 80.78it/s, loss=0.57, v_num=3, val_loss=4.41, val_acc=0.0195]\n",
            "Epoch 0:  87% 2222/2542 [00:27<00:03, 81.00it/s, loss=0.57, v_num=3, val_loss=4.41, val_acc=0.0195]\n",
            "Epoch 0:  88% 2238/2542 [00:27<00:03, 81.26it/s, loss=0.57, v_num=3, val_loss=4.41, val_acc=0.0195]\n",
            "Epoch 0:  89% 2254/2542 [00:27<00:03, 81.49it/s, loss=0.57, v_num=3, val_loss=4.41, val_acc=0.0195]\n",
            "Epoch 0:  89% 2270/2542 [00:27<00:03, 81.74it/s, loss=0.57, v_num=3, val_loss=4.41, val_acc=0.0195]\n",
            "Epoch 0:  90% 2286/2542 [00:27<00:03, 81.94it/s, loss=0.57, v_num=3, val_loss=4.41, val_acc=0.0195]\n",
            "Epoch 0:  91% 2302/2542 [00:28<00:02, 82.16it/s, loss=0.57, v_num=3, val_loss=4.41, val_acc=0.0195]\n",
            "Epoch 0:  91% 2318/2542 [00:28<00:02, 82.36it/s, loss=0.57, v_num=3, val_loss=4.41, val_acc=0.0195]\n",
            "Validating:  56% 285/509 [00:02<00:01, 128.32it/s]\u001b[A\n",
            "Epoch 0:  92% 2334/2542 [00:28<00:02, 82.58it/s, loss=0.57, v_num=3, val_loss=4.41, val_acc=0.0195]\n",
            "Epoch 0:  92% 2350/2542 [00:28<00:02, 82.79it/s, loss=0.57, v_num=3, val_loss=4.41, val_acc=0.0195]\n",
            "Epoch 0:  93% 2366/2542 [00:28<00:02, 83.01it/s, loss=0.57, v_num=3, val_loss=4.41, val_acc=0.0195]\n",
            "Epoch 0:  94% 2382/2542 [00:28<00:01, 83.23it/s, loss=0.57, v_num=3, val_loss=4.41, val_acc=0.0195]\n",
            "Epoch 0:  94% 2398/2542 [00:28<00:01, 83.44it/s, loss=0.57, v_num=3, val_loss=4.41, val_acc=0.0195]\n",
            "Epoch 0:  95% 2414/2542 [00:28<00:01, 83.65it/s, loss=0.57, v_num=3, val_loss=4.41, val_acc=0.0195]\n",
            "Epoch 0:  96% 2430/2542 [00:28<00:01, 83.89it/s, loss=0.57, v_num=3, val_loss=4.41, val_acc=0.0195]\n",
            "Epoch 0:  96% 2447/2542 [00:29<00:01, 84.18it/s, loss=0.57, v_num=3, val_loss=4.41, val_acc=0.0195]\n",
            "Epoch 0:  97% 2464/2542 [00:29<00:00, 84.40it/s, loss=0.57, v_num=3, val_loss=4.41, val_acc=0.0195]\n",
            "Epoch 0:  98% 2481/2542 [00:29<00:00, 84.63it/s, loss=0.57, v_num=3, val_loss=4.41, val_acc=0.0195]\n",
            "Epoch 0:  98% 2498/2542 [00:29<00:00, 84.88it/s, loss=0.57, v_num=3, val_loss=4.41, val_acc=0.0195]\n",
            "Validating:  91% 465/509 [00:03<00:00, 143.11it/s]\u001b[A\n",
            "Epoch 0:  99% 2515/2542 [00:29<00:00, 85.13it/s, loss=0.57, v_num=3, val_loss=4.41, val_acc=0.0195]\n",
            "Epoch 0: 100% 2542/2542 [00:29<00:00, 85.10it/s, loss=0.57, v_num=3, val_loss=0.572, val_acc=0.789]\n",
            "Epoch 1:  80% 2033/2542 [00:25<00:06, 78.30it/s, loss=0.508, v_num=3, val_loss=0.572, val_acc=0.789]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/509 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 1:  80% 2040/2542 [00:26<00:06, 77.43it/s, loss=0.508, v_num=3, val_loss=0.572, val_acc=0.789]\n",
            "Epoch 1:  81% 2057/2542 [00:26<00:06, 77.76it/s, loss=0.508, v_num=3, val_loss=0.572, val_acc=0.789]\n",
            "Epoch 1:  82% 2074/2542 [00:26<00:05, 78.03it/s, loss=0.508, v_num=3, val_loss=0.572, val_acc=0.789]\n",
            "Validating:   8% 42/509 [00:00<00:23, 19.71it/s]\u001b[A\n",
            "Epoch 1:  82% 2091/2542 [00:26<00:05, 78.30it/s, loss=0.508, v_num=3, val_loss=0.572, val_acc=0.789]\n",
            "Epoch 1:  83% 2108/2542 [00:26<00:05, 78.58it/s, loss=0.508, v_num=3, val_loss=0.572, val_acc=0.789]\n",
            "Epoch 1:  84% 2125/2542 [00:26<00:05, 78.86it/s, loss=0.508, v_num=3, val_loss=0.572, val_acc=0.789]\n",
            "Epoch 1:  84% 2142/2542 [00:27<00:05, 79.09it/s, loss=0.508, v_num=3, val_loss=0.572, val_acc=0.789]\n",
            "Epoch 1:  85% 2159/2542 [00:27<00:04, 79.34it/s, loss=0.508, v_num=3, val_loss=0.572, val_acc=0.789]\n",
            "Epoch 1:  86% 2176/2542 [00:27<00:04, 79.61it/s, loss=0.508, v_num=3, val_loss=0.572, val_acc=0.789]\n",
            "Validating:  28% 144/509 [00:01<00:04, 91.08it/s]\u001b[A\n",
            "Epoch 1:  86% 2193/2542 [00:27<00:04, 79.87it/s, loss=0.508, v_num=3, val_loss=0.572, val_acc=0.789]\n",
            "Epoch 1:  87% 2210/2542 [00:27<00:04, 80.14it/s, loss=0.508, v_num=3, val_loss=0.572, val_acc=0.789]\n",
            "Epoch 1:  88% 2227/2542 [00:27<00:03, 80.40it/s, loss=0.508, v_num=3, val_loss=0.572, val_acc=0.789]\n",
            "Epoch 1:  88% 2244/2542 [00:27<00:03, 80.63it/s, loss=0.508, v_num=3, val_loss=0.572, val_acc=0.789]\n",
            "Epoch 1:  89% 2261/2542 [00:27<00:03, 80.90it/s, loss=0.508, v_num=3, val_loss=0.572, val_acc=0.789]\n",
            "Validating:  45% 230/509 [00:01<00:02, 127.88it/s]\u001b[A\n",
            "Epoch 1:  90% 2278/2542 [00:28<00:03, 81.12it/s, loss=0.508, v_num=3, val_loss=0.572, val_acc=0.789]\n",
            "Epoch 1:  90% 2295/2542 [00:28<00:03, 81.35it/s, loss=0.508, v_num=3, val_loss=0.572, val_acc=0.789]\n",
            "Epoch 1:  91% 2312/2542 [00:28<00:02, 81.59it/s, loss=0.508, v_num=3, val_loss=0.572, val_acc=0.789]\n",
            "Epoch 1:  92% 2329/2542 [00:28<00:02, 81.83it/s, loss=0.508, v_num=3, val_loss=0.572, val_acc=0.789]\n",
            "Epoch 1:  92% 2346/2542 [00:28<00:02, 82.07it/s, loss=0.508, v_num=3, val_loss=0.572, val_acc=0.789]\n",
            "Epoch 1:  93% 2363/2542 [00:28<00:02, 82.30it/s, loss=0.508, v_num=3, val_loss=0.572, val_acc=0.789]\n",
            "Validating:  65% 331/509 [00:02<00:01, 135.87it/s]\u001b[A\n",
            "Epoch 1:  94% 2380/2542 [00:28<00:01, 82.52it/s, loss=0.508, v_num=3, val_loss=0.572, val_acc=0.789]\n",
            "Epoch 1:  94% 2397/2542 [00:28<00:01, 82.76it/s, loss=0.508, v_num=3, val_loss=0.572, val_acc=0.789]\n",
            "Epoch 1:  95% 2414/2542 [00:29<00:01, 82.97it/s, loss=0.508, v_num=3, val_loss=0.572, val_acc=0.789]\n",
            "Epoch 1:  96% 2431/2542 [00:29<00:01, 83.20it/s, loss=0.508, v_num=3, val_loss=0.572, val_acc=0.789]\n",
            "Epoch 1:  96% 2448/2542 [00:29<00:01, 83.45it/s, loss=0.508, v_num=3, val_loss=0.572, val_acc=0.789]\n",
            "Validating:  82% 417/509 [00:03<00:00, 136.42it/s]\u001b[A\n",
            "Epoch 1:  97% 2465/2542 [00:29<00:00, 83.66it/s, loss=0.508, v_num=3, val_loss=0.572, val_acc=0.789]\n",
            "Epoch 1:  98% 2482/2542 [00:29<00:00, 83.89it/s, loss=0.508, v_num=3, val_loss=0.572, val_acc=0.789]\n",
            "Epoch 1:  98% 2499/2542 [00:29<00:00, 84.10it/s, loss=0.508, v_num=3, val_loss=0.572, val_acc=0.789]\n",
            "Epoch 1:  99% 2516/2542 [00:29<00:00, 84.34it/s, loss=0.508, v_num=3, val_loss=0.572, val_acc=0.789]\n",
            "Epoch 1: 100% 2533/2542 [00:29<00:00, 84.52it/s, loss=0.508, v_num=3, val_loss=0.572, val_acc=0.789]\n",
            "Epoch 1: 100% 2542/2542 [00:30<00:00, 84.19it/s, loss=0.508, v_num=3, val_loss=0.528, val_acc=0.798]\n",
            "Epoch 2:  80% 2033/2542 [00:26<00:06, 77.93it/s, loss=0.463, v_num=3, val_loss=0.528, val_acc=0.798]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/509 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 2:  80% 2040/2542 [00:26<00:06, 77.15it/s, loss=0.463, v_num=3, val_loss=0.528, val_acc=0.798]\n",
            "Epoch 2:  81% 2057/2542 [00:26<00:06, 77.41it/s, loss=0.463, v_num=3, val_loss=0.528, val_acc=0.798]\n",
            "Validating:   5% 26/509 [00:00<00:36, 13.08it/s]\u001b[A\n",
            "Epoch 2:  82% 2074/2542 [00:26<00:06, 77.33it/s, loss=0.463, v_num=3, val_loss=0.528, val_acc=0.798]\n",
            "Epoch 2:  82% 2091/2542 [00:26<00:05, 77.59it/s, loss=0.463, v_num=3, val_loss=0.528, val_acc=0.798]\n",
            "Epoch 2:  83% 2108/2542 [00:27<00:05, 77.89it/s, loss=0.463, v_num=3, val_loss=0.528, val_acc=0.798]\n",
            "Epoch 2:  84% 2125/2542 [00:27<00:05, 78.17it/s, loss=0.463, v_num=3, val_loss=0.528, val_acc=0.798]\n",
            "Validating:  18% 92/509 [00:00<00:08, 50.01it/s]\u001b[A\n",
            "Epoch 2:  84% 2142/2542 [00:27<00:05, 78.44it/s, loss=0.463, v_num=3, val_loss=0.528, val_acc=0.798]\n",
            "Epoch 2:  85% 2159/2542 [00:27<00:04, 78.70it/s, loss=0.463, v_num=3, val_loss=0.528, val_acc=0.798]\n",
            "Epoch 2:  86% 2176/2542 [00:27<00:04, 78.97it/s, loss=0.463, v_num=3, val_loss=0.528, val_acc=0.798]\n",
            "Epoch 2:  86% 2193/2542 [00:27<00:04, 79.18it/s, loss=0.463, v_num=3, val_loss=0.528, val_acc=0.798]\n",
            "Epoch 2:  87% 2210/2542 [00:27<00:04, 79.46it/s, loss=0.463, v_num=3, val_loss=0.528, val_acc=0.798]\n",
            "Validating:  35% 177/509 [00:01<00:02, 111.68it/s]\u001b[A\n",
            "Epoch 2:  88% 2227/2542 [00:27<00:03, 79.70it/s, loss=0.463, v_num=3, val_loss=0.528, val_acc=0.798]\n",
            "Epoch 2:  88% 2244/2542 [00:28<00:03, 79.98it/s, loss=0.463, v_num=3, val_loss=0.528, val_acc=0.798]\n",
            "Epoch 2:  89% 2262/2542 [00:28<00:03, 80.33it/s, loss=0.463, v_num=3, val_loss=0.528, val_acc=0.798]\n",
            "Epoch 2:  90% 2280/2542 [00:28<00:03, 80.56it/s, loss=0.463, v_num=3, val_loss=0.528, val_acc=0.798]\n",
            "Epoch 2:  90% 2298/2542 [00:28<00:03, 80.90it/s, loss=0.463, v_num=3, val_loss=0.528, val_acc=0.798]\n",
            "Epoch 2:  91% 2316/2542 [00:28<00:02, 81.22it/s, loss=0.463, v_num=3, val_loss=0.528, val_acc=0.798]\n",
            "Epoch 2:  92% 2334/2542 [00:28<00:02, 81.53it/s, loss=0.463, v_num=3, val_loss=0.528, val_acc=0.798]\n",
            "Epoch 2:  93% 2352/2542 [00:28<00:02, 81.85it/s, loss=0.463, v_num=3, val_loss=0.528, val_acc=0.798]\n",
            "Validating:  63% 320/509 [00:02<00:01, 154.57it/s]\u001b[A\n",
            "Epoch 2:  93% 2370/2542 [00:28<00:02, 82.13it/s, loss=0.463, v_num=3, val_loss=0.528, val_acc=0.798]\n",
            "Epoch 2:  94% 2388/2542 [00:28<00:01, 82.44it/s, loss=0.463, v_num=3, val_loss=0.528, val_acc=0.798]\n",
            "Epoch 2:  95% 2406/2542 [00:29<00:01, 82.70it/s, loss=0.463, v_num=3, val_loss=0.528, val_acc=0.798]\n",
            "Epoch 2:  95% 2424/2542 [00:29<00:01, 82.97it/s, loss=0.463, v_num=3, val_loss=0.528, val_acc=0.798]\n",
            "Epoch 2:  96% 2442/2542 [00:29<00:01, 83.26it/s, loss=0.463, v_num=3, val_loss=0.528, val_acc=0.798]\n",
            "Epoch 2:  97% 2460/2542 [00:29<00:00, 83.55it/s, loss=0.463, v_num=3, val_loss=0.528, val_acc=0.798]\n",
            "Epoch 2:  97% 2478/2542 [00:29<00:00, 83.85it/s, loss=0.463, v_num=3, val_loss=0.528, val_acc=0.798]\n",
            "Epoch 2:  98% 2496/2542 [00:29<00:00, 84.14it/s, loss=0.463, v_num=3, val_loss=0.528, val_acc=0.798]\n",
            "Epoch 2:  99% 2514/2542 [00:29<00:00, 84.44it/s, loss=0.463, v_num=3, val_loss=0.528, val_acc=0.798]\n",
            "Epoch 2: 100% 2532/2542 [00:29<00:00, 84.74it/s, loss=0.463, v_num=3, val_loss=0.528, val_acc=0.798]\n",
            "Epoch 2: 100% 2542/2542 [00:30<00:00, 84.46it/s, loss=0.463, v_num=3, val_loss=0.509, val_acc=0.805]\n",
            "Epoch 3:  80% 2034/2542 [00:26<00:06, 77.16it/s, loss=0.437, v_num=3, val_loss=0.509, val_acc=0.805]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/509 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:   0% 1/509 [00:00<01:27,  5.80it/s]\u001b[A\n",
            "Epoch 3:  81% 2052/2542 [00:26<00:06, 77.02it/s, loss=0.437, v_num=3, val_loss=0.509, val_acc=0.805]\n",
            "Epoch 3:  81% 2070/2542 [00:26<00:06, 77.36it/s, loss=0.437, v_num=3, val_loss=0.509, val_acc=0.805]\n",
            "Epoch 3:  82% 2088/2542 [00:26<00:05, 77.72it/s, loss=0.437, v_num=3, val_loss=0.509, val_acc=0.805]\n",
            "Epoch 3:  83% 2106/2542 [00:26<00:05, 78.04it/s, loss=0.437, v_num=3, val_loss=0.509, val_acc=0.805]\n",
            "Epoch 3:  84% 2124/2542 [00:27<00:05, 78.33it/s, loss=0.437, v_num=3, val_loss=0.509, val_acc=0.805]\n",
            "Epoch 3:  84% 2142/2542 [00:27<00:05, 78.65it/s, loss=0.437, v_num=3, val_loss=0.509, val_acc=0.805]\n",
            "Epoch 3:  85% 2160/2542 [00:27<00:04, 78.98it/s, loss=0.437, v_num=3, val_loss=0.509, val_acc=0.805]\n",
            "Validating:  25% 127/509 [00:00<00:06, 61.97it/s]\u001b[A\n",
            "Epoch 3:  86% 2178/2542 [00:27<00:04, 79.31it/s, loss=0.437, v_num=3, val_loss=0.509, val_acc=0.805]\n",
            "Epoch 3:  86% 2196/2542 [00:27<00:04, 79.67it/s, loss=0.437, v_num=3, val_loss=0.509, val_acc=0.805]\n",
            "Epoch 3:  87% 2214/2542 [00:27<00:04, 79.97it/s, loss=0.437, v_num=3, val_loss=0.509, val_acc=0.805]\n",
            "Epoch 3:  88% 2232/2542 [00:27<00:03, 80.30it/s, loss=0.437, v_num=3, val_loss=0.509, val_acc=0.805]\n",
            "Epoch 3:  89% 2250/2542 [00:27<00:03, 80.62it/s, loss=0.437, v_num=3, val_loss=0.509, val_acc=0.805]\n",
            "Epoch 3:  89% 2268/2542 [00:28<00:03, 80.97it/s, loss=0.437, v_num=3, val_loss=0.509, val_acc=0.805]\n",
            "Epoch 3:  90% 2286/2542 [00:28<00:03, 81.27it/s, loss=0.437, v_num=3, val_loss=0.509, val_acc=0.805]\n",
            "Epoch 3:  91% 2304/2542 [00:28<00:02, 81.49it/s, loss=0.437, v_num=3, val_loss=0.509, val_acc=0.805]\n",
            "Epoch 3:  91% 2322/2542 [00:28<00:02, 81.77it/s, loss=0.437, v_num=3, val_loss=0.509, val_acc=0.805]\n",
            "Validating:  57% 290/509 [00:02<00:01, 139.43it/s]\u001b[A\n",
            "Epoch 3:  92% 2340/2542 [00:28<00:02, 82.02it/s, loss=0.437, v_num=3, val_loss=0.509, val_acc=0.805]\n",
            "Epoch 3:  93% 2358/2542 [00:28<00:02, 82.28it/s, loss=0.437, v_num=3, val_loss=0.509, val_acc=0.805]\n",
            "Epoch 3:  93% 2376/2542 [00:28<00:02, 82.53it/s, loss=0.437, v_num=3, val_loss=0.509, val_acc=0.805]\n",
            "Epoch 3:  94% 2394/2542 [00:28<00:01, 82.80it/s, loss=0.437, v_num=3, val_loss=0.509, val_acc=0.805]\n",
            "Epoch 3:  95% 2412/2542 [00:29<00:01, 83.11it/s, loss=0.437, v_num=3, val_loss=0.509, val_acc=0.805]\n",
            "Epoch 3:  96% 2430/2542 [00:29<00:01, 83.39it/s, loss=0.437, v_num=3, val_loss=0.509, val_acc=0.805]\n",
            "Epoch 3:  96% 2448/2542 [00:29<00:01, 83.67it/s, loss=0.437, v_num=3, val_loss=0.509, val_acc=0.805]\n",
            "Validating:  82% 415/509 [00:02<00:00, 147.45it/s]\u001b[A\n",
            "Epoch 3:  97% 2466/2542 [00:29<00:00, 83.89it/s, loss=0.437, v_num=3, val_loss=0.509, val_acc=0.805]\n",
            "Epoch 3:  98% 2484/2542 [00:29<00:00, 84.11it/s, loss=0.437, v_num=3, val_loss=0.509, val_acc=0.805]\n",
            "Epoch 3:  98% 2502/2542 [00:29<00:00, 84.36it/s, loss=0.437, v_num=3, val_loss=0.509, val_acc=0.805]\n",
            "Epoch 3:  99% 2520/2542 [00:29<00:00, 84.56it/s, loss=0.437, v_num=3, val_loss=0.509, val_acc=0.805]\n",
            "Epoch 3: 100% 2538/2542 [00:29<00:00, 84.82it/s, loss=0.437, v_num=3, val_loss=0.509, val_acc=0.805]\n",
            "Epoch 3: 100% 2542/2542 [00:30<00:00, 84.43it/s, loss=0.437, v_num=3, val_loss=0.498, val_acc=0.807]\n",
            "Epoch 4:  80% 2034/2542 [00:26<00:06, 77.15it/s, loss=0.408, v_num=3, val_loss=0.498, val_acc=0.807]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/509 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:   0% 1/509 [00:00<01:30,  5.59it/s]\u001b[A\n",
            "Epoch 4:  81% 2052/2542 [00:26<00:06, 77.00it/s, loss=0.408, v_num=3, val_loss=0.498, val_acc=0.807]\n",
            "Epoch 4:  81% 2070/2542 [00:26<00:06, 77.33it/s, loss=0.408, v_num=3, val_loss=0.498, val_acc=0.807]\n",
            "Epoch 4:  82% 2088/2542 [00:26<00:05, 77.69it/s, loss=0.408, v_num=3, val_loss=0.498, val_acc=0.807]\n",
            "Epoch 4:  83% 2106/2542 [00:27<00:05, 77.99it/s, loss=0.408, v_num=3, val_loss=0.498, val_acc=0.807]\n",
            "Epoch 4:  84% 2124/2542 [00:27<00:05, 78.30it/s, loss=0.408, v_num=3, val_loss=0.498, val_acc=0.807]\n",
            "Epoch 4:  84% 2142/2542 [00:27<00:05, 78.56it/s, loss=0.408, v_num=3, val_loss=0.498, val_acc=0.807]\n",
            "Validating:  22% 111/509 [00:00<00:08, 47.07it/s]\u001b[A\n",
            "Epoch 4:  85% 2160/2542 [00:27<00:04, 78.83it/s, loss=0.408, v_num=3, val_loss=0.498, val_acc=0.807]\n",
            "Epoch 4:  86% 2178/2542 [00:27<00:04, 79.10it/s, loss=0.408, v_num=3, val_loss=0.498, val_acc=0.807]\n",
            "Epoch 4:  86% 2196/2542 [00:27<00:04, 79.39it/s, loss=0.408, v_num=3, val_loss=0.498, val_acc=0.807]\n",
            "Epoch 4:  87% 2214/2542 [00:27<00:04, 79.67it/s, loss=0.408, v_num=3, val_loss=0.498, val_acc=0.807]\n",
            "Epoch 4:  88% 2232/2542 [00:27<00:03, 80.01it/s, loss=0.408, v_num=3, val_loss=0.498, val_acc=0.807]\n",
            "Validating:  39% 199/509 [00:01<00:02, 117.32it/s]\u001b[A\n",
            "Epoch 4:  89% 2250/2542 [00:28<00:03, 80.29it/s, loss=0.408, v_num=3, val_loss=0.498, val_acc=0.807]\n",
            "Epoch 4:  89% 2268/2542 [00:28<00:03, 80.57it/s, loss=0.408, v_num=3, val_loss=0.498, val_acc=0.807]\n",
            "Epoch 4:  90% 2286/2542 [00:28<00:03, 80.83it/s, loss=0.408, v_num=3, val_loss=0.498, val_acc=0.807]\n",
            "Epoch 4:  91% 2304/2542 [00:28<00:02, 81.09it/s, loss=0.408, v_num=3, val_loss=0.498, val_acc=0.807]\n",
            "Epoch 4:  91% 2322/2542 [00:28<00:02, 81.32it/s, loss=0.408, v_num=3, val_loss=0.498, val_acc=0.807]\n",
            "Validating:  57% 289/509 [00:02<00:01, 132.64it/s]\u001b[A\n",
            "Epoch 4:  92% 2340/2542 [00:28<00:02, 81.58it/s, loss=0.408, v_num=3, val_loss=0.498, val_acc=0.807]\n",
            "Epoch 4:  93% 2358/2542 [00:28<00:02, 81.83it/s, loss=0.408, v_num=3, val_loss=0.498, val_acc=0.807]\n",
            "Epoch 4:  93% 2376/2542 [00:28<00:02, 82.07it/s, loss=0.408, v_num=3, val_loss=0.498, val_acc=0.807]\n",
            "Epoch 4:  94% 2394/2542 [00:29<00:01, 82.33it/s, loss=0.408, v_num=3, val_loss=0.498, val_acc=0.807]\n",
            "Validating:  71% 362/509 [00:02<00:01, 135.05it/s]\u001b[A\n",
            "Epoch 4:  95% 2412/2542 [00:29<00:01, 82.54it/s, loss=0.408, v_num=3, val_loss=0.498, val_acc=0.807]\n",
            "Epoch 4:  96% 2430/2542 [00:29<00:01, 82.78it/s, loss=0.408, v_num=3, val_loss=0.498, val_acc=0.807]\n",
            "Epoch 4:  96% 2448/2542 [00:29<00:01, 83.01it/s, loss=0.408, v_num=3, val_loss=0.498, val_acc=0.807]\n",
            "Validating:  82% 418/509 [00:03<00:00, 134.92it/s]\u001b[A\n",
            "Epoch 4:  97% 2466/2542 [00:29<00:00, 83.24it/s, loss=0.408, v_num=3, val_loss=0.498, val_acc=0.807]\n",
            "Epoch 4:  98% 2484/2542 [00:29<00:00, 83.48it/s, loss=0.408, v_num=3, val_loss=0.498, val_acc=0.807]\n",
            "Epoch 4:  98% 2502/2542 [00:29<00:00, 83.73it/s, loss=0.408, v_num=3, val_loss=0.498, val_acc=0.807]\n",
            "Epoch 4:  99% 2520/2542 [00:29<00:00, 84.01it/s, loss=0.408, v_num=3, val_loss=0.498, val_acc=0.807]\n",
            "Epoch 4: 100% 2542/2542 [00:30<00:00, 84.10it/s, loss=0.408, v_num=3, val_loss=0.505, val_acc=0.807]\n",
            "Epoch 4: 100% 2542/2542 [00:30<00:00, 84.10it/s, loss=0.408, v_num=3, val_loss=0.505, val_acc=0.807]\n",
            "Testing: 100% 422/422 [00:02<00:00, 149.26it/s]\n",
            "--------------------------------------------------------------------------------\n",
            "DATALOADER:0 TEST RESULTS\n",
            "{'test_acc': 0.8061420917510986}\n",
            "--------------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}